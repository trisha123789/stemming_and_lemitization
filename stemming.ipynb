{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOziL4TmAdd4Bdgq5jBqhiQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trisha123789/stemming_and_lemitization/blob/main/stemming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MIxtSAf7bKT"
      },
      "outputs": [],
      "source": [
        "#stemming using snowball stemming and porter stemming"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "Xzzz5yI9Admo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcYjtYDdAe6J",
        "outputId": "2c08f732-1d67-4d8f-cff3-267e923f356a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "nbVxSNckGMQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "pOjNgYoxGThk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ps = PorterStemmer()"
      ],
      "metadata": {
        "id": "aerfJyd8GYMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"running playing rizzing playlist\""
      ],
      "metadata": {
        "id": "-mBT9cNsGmXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(text)"
      ],
      "metadata": {
        "id": "Bza02SsuGhwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stems = [ps.stem(word) for word in words]"
      ],
      "metadata": {
        "id": "3N8Qg_PSGsjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(stems)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KoJyja_HBQE",
        "outputId": "f3f46373-e024-4fe5-e6ba-d324a554ddb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['run', 'play', 'rizz', 'playlist']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SnowBall Stemmer"
      ],
      "metadata": {
        "id": "4oRHw8ODHCaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer"
      ],
      "metadata": {
        "id": "I0EEuU4QHJ-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sbs = SnowballStemmer('english')"
      ],
      "metadata": {
        "id": "nusZocZ9HN-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"running skipping playlist ennumeration\"\n"
      ],
      "metadata": {
        "id": "jvWLwRhIHRuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(text)"
      ],
      "metadata": {
        "id": "xu4xj3hGHaUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stems = [sbs.stem(token) for token in tokens]"
      ],
      "metadata": {
        "id": "ijNZYLT6HfB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(stems)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uekms9qAHpPg",
        "outputId": "f9d6539e-7153-4512-f408-963466b47429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['run', 'skip', 'playlist', 'ennumer']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#difference between porter and snowballstemmer is snowball stemmer avids the over stemming it is more systematic"
      ],
      "metadata": {
        "id": "PbsTA53tHqjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#there are two types of lemmitization basic and pos"
      ],
      "metadata": {
        "id": "U0d4rqyBH8DJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "_84ZgR7LIiMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet"
      ],
      "metadata": {
        "id": "vmZyekGRaSjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsaKeZ-6IlT0",
        "outputId": "ecd6233a-baef-4d28-ecc9-083a57bd61b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"running jogging flying\""
      ],
      "metadata": {
        "id": "UjPQk_tlInct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(text)"
      ],
      "metadata": {
        "id": "8ttoy1DRZQrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wnl = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "gSSP8Ty8ZXTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# stemming donot understand grammatical rules syntaxes but lemmitization does"
      ],
      "metadata": {
        "id": "Yg9gDu01fDPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#pos stands for parts of speech\n",
        "\n",
        "\n",
        "POS = Part of Speech\n",
        "\n",
        "It means the grammatical category of a word in a sentence.\n",
        "\n",
        "Every word in English belongs to a POS category like:\n",
        "\n",
        "Noun (person, place, thing)\n",
        "\n",
        "Verb (action or state)\n",
        "\n",
        "Adjective (describes a noun)\n",
        "\n",
        "Adverb (describes a verb/adjective)\n",
        "\n",
        "Pronoun\n",
        "\n",
        "Preposition\n",
        "\n",
        "Conjunction\n",
        "\n",
        "Determiner\n",
        "\n",
        "Interjection\n",
        "\n",
        "In short:\n",
        " POS tells the role a word is playing in a sentence.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4Vag_dRmg8YI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iISCsbNwZmYP",
        "outputId": "e47f4ffe-8891-4ed0-a503-c4dc5aa351bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lem = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "HgrZUIZUZyxn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"i saw a very beautiful girl yesterday studies\"\n"
      ],
      "metadata": {
        "id": "Am06kLSWfr_H"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(text)"
      ],
      "metadata": {
        "id": "25ZoRoNfis5q"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemitized_words = [lem.lemmatize(token) for token in tokens]"
      ],
      "metadata": {
        "id": "p94BeOQCiyR0"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"lemitized words :\",lemitized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP90LVZMi8TY",
        "outputId": "8f71c285-21cf-4ea9-bc71-a99daba5f50a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemitized words : ['i', 'saw', 'a', 'very', 'beautiful', 'girl', 'yesterday', 'study']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mye68jWLjA0-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}